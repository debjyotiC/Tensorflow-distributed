## Tensorflow Distrubited 
This repository contains code for distributed computing with Tensorflow 
 

## Dependencies required 
  1. `Tensorflow v2.0` : https://www.tensorflow.org/install


## Essentials:
TensorFlow supports distributed computing, this enables execution of a computational graph on a totally different process, which can be a completely different server. In addition, say for example you have a powerful `GPU` in your home desktop and want to do some training on that using the data generated by your not so power `Raspberry Pi` that is running your current robotics project, tensorflow distributed helps you to do just that! 

TensorFlow works in the form of a server-client model, to be able to compute parts of the graph on a different server we need create a bunch of workers that will perform the heavy lifting on the `Raspberry Pi's` behalf. The server doing all the heavy lifting is called a `worker` and the one providing the graph is called a `parameter server`, data flowing from a `parameter server` to the `worker` is called a forward pass where as the opposit is called a backward pass.

An example script to run on a single process, and then we will move to multiple processes.

```
import tensorflow as tf #import Tensorflow

a = tf.constant(3.0) #declare constants
b = tf.constant(2.0)

x = tf.add(a, b) #add
y = tf.multiply(a, b) #multiply
z = tf.add(x, y) #add

with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True)) as sess:
    print(sess.run(z))

```
In order to distribute you need to create a session on one of those `parameter servers`, and it will compute the graph, possibly distributing parts of it to the `worker` clusters on the server.
<img src="https://github.com/debjyotiC/Tensorflow-distributed/blob/master/images/server-clinet-model.png" width="580">

